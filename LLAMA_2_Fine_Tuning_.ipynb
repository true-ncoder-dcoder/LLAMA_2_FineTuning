{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyM5x/5ndGe5brfT1tSx+4X4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/true-ncoder-dcoder/LLAMA_2_FineTuning/blob/main/LLAMA_2_Fine_Tuning_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers peft bitsandbytes trl deepeval evaluate"
      ],
      "metadata": {
        "id": "yCGsBhH97F_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    TrainingArguments,\n",
        "    pipeline,\n",
        "    Trainer\n",
        ")\n",
        "from peft import LoraConfig\n",
        "from trl import SFTTrainer\n",
        "import evaluate"
      ],
      "metadata": {
        "id": "WvK-NXMV7asO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#################################\n",
        "### Setup Quantization Config ###\n",
        "#################################\n",
        "compute_dtype = getattr(torch, \"float16\")\n",
        "quant_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=compute_dtype,\n",
        "    bnb_4bit_use_double_quant=False,\n",
        ")"
      ],
      "metadata": {
        "id": "USc3FyM17aed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model_name = \"NousResearch/Llama-2-7b-chat-hf\"\n",
        "llama_2 = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model_name,\n",
        "    quantization_config=quant_config,\n",
        "    device_map={\"\": 0},\n",
        "    token = \"XXXXXXXXXXXXX\" #Replace XXXXXXX with HF Token\n",
        ")"
      ],
      "metadata": {
        "id": "Thcpo35r9IQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "  base_model_name,\n",
        "  trust_remote_code=True,\n",
        "  token = \"XXXXXXXXXXXXX\" #Replace XXXXXXX with HF Token\n",
        ")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\""
      ],
      "metadata": {
        "id": "tbJK7G9i-WMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####################\n",
        "### Load Dataset ###\n",
        "####################\n",
        "train_dataset_name = \"mlabonne/guanaco-llama2-1k\"\n",
        "train_dataset = load_dataset(train_dataset_name, split=\"train\")"
      ],
      "metadata": {
        "id": "QaqpPw5b-eKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#########################################\n",
        "### Load LoRA Configurations for PEFT ###\n",
        "#########################################\n",
        "peft_config = LoraConfig(\n",
        "    lora_alpha = 16\n",
        "    lora_dropout=0.1,\n",
        "    r=64,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")"
      ],
      "metadata": {
        "id": "rA7SyoOo-6oZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# import accuracy evaluation metric\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "\n",
        "# define an evaluation function to pass into trainer later\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "    return {\"accuracy\": accuracy.compute(predictions=predictions,\n",
        "                                          references=labels)}"
      ],
      "metadata": {
        "id": "WIoKHzWwvrYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_arguments = TrainingArguments(\n",
        "    output_dir=\"./tuning_results\",\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=4,\n",
        "    gradient_accumulation_steps=1,\n",
        "    optim=\"paged_adamw_32bit\",\n",
        "    save_steps=25,\n",
        "    logging_steps=25,\n",
        "    learning_rate=2e-4,\n",
        "    weight_decay=0.001,\n",
        "    fp16=False,\n",
        "    bf16=False,\n",
        "    max_grad_norm=0.3,\n",
        "    max_steps=-1,\n",
        "    warmup_ratio=0.03,\n",
        "    group_by_length=True,\n",
        "    lr_scheduler_type=\"constant\"\n",
        ")\n",
        "trainer = SFTTrainer(\n",
        "    model=llama_2,\n",
        "    train_dataset=train_dataset,\n",
        "    peft_config=peft_config,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=None,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_arguments,\n",
        "    packing=False,\n",
        ")"
      ],
      "metadata": {
        "id": "qH8MXM6Z--xP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"HF_TOKEN\"] = \"XXXXXXXXXXXXX\" #Replace XXXXXXX with HF Token\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "KYoo6PGj_2LQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o5S6D9YuJtb3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}